{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "from numpy import linalg as LA\n",
    "import sys\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AdmissionDataset/data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>317</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334</td>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>326</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232</td>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0         242        317          103                  2  2.5   2.0  8.15   \n",
       "1         334        319          108                  3  3.0   3.5  8.54   \n",
       "2           4        322          110                  3  3.5   2.5  8.67   \n",
       "3          45        326          113                  5  4.5   4.0  9.40   \n",
       "4         232        319          106                  3  3.5   2.5  8.33   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         0              0.65  \n",
       "1         1              0.71  \n",
       "2         1              0.80  \n",
       "3         1              0.91  \n",
       "4         1              0.74  "
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
    "train,test = train_test_split(df, test_size=0.2)\n",
    "train_y = train['Chance of Admit ']\n",
    "train = train.drop('Serial No.',axis=1)\n",
    "train = train.drop('Chance of Admit ',axis=1)\n",
    "test_y = test['Chance of Admit ']\n",
    "test = test.drop('Serial No.',axis=1)\n",
    "test = test.drop('Chance of Admit ',axis=1)\n",
    "train_y=np.where(train_y>=0.5,1,0)\n",
    "test_y=np.where(test_y>=0.5,1,0)\n",
    "# train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 8)"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=train.values\n",
    "X1=test.values\n",
    "# print(X)\n",
    "z1= np.ones((len(test),1))\n",
    "X1= np.append(z1,X1, axis=1)\n",
    "z = np.ones((len(train),1))\n",
    "X=np.append(z,X, axis=1)\n",
    "Y=train_y\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "# print(beta)\n",
    "\n",
    "def loss(h, y):\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "y=train_y\n",
    "beta = np.zeros(X.shape[1]) \n",
    "print((X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta, num_iter = grad_desc(X, y, beta)\n",
    "lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.74021672, -0.52520423,  3.90299082,  7.43560587,  4.52974803,\n",
       "        9.59828804,  6.13153473,  5.6278316 ])"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(30000):\n",
    "    z = np.dot(X, beta)\n",
    "#     print(z.shape)\n",
    "    h = sigmoid(z)\n",
    "    gradient = np.dot(X.T, (h - y)) / y.size\n",
    "    beta -= lr * gradient\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.dot(X1, beta)\n",
    "h = sigmoid(z)\n",
    "ans=sigmoid(np.dot(X1, beta))\n",
    "ans=np.where(ans>=0.5,1,0)\n",
    "# ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Logistic Regression:  0.9222222222222223\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in range(len(X1)):\n",
    "    if (test_y[i]==ans[i]):\n",
    "        c+=1\n",
    "accu=c/len(X1)\n",
    "print(\"Accuracy using Logistic Regression: \",accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc using SKlearn:  0.9222222222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keshu/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LogisticRegression(solver='lbfgs') \n",
    "# train the model using the training sets \n",
    "reg.fit(train,train_y)\n",
    "pred2=reg.predict(test)\n",
    "print(\"Acc using SKlearn: \", accuracy_score(test_y,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logisticRegr.fit(train, train_y)\n",
    "# logisticRegr.predict(test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# X = df.iloc[:, :-1].values  \n",
    "# y = df.iloc[:, -1].values \n",
    "# y=np.where(y>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split  \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def euclidDistance(val1, val2, entirelength):\n",
    "#     distance = 0\n",
    "#     for x in range(entirelength):\n",
    "#         distance += pow((val1[x] - val2[x]), 2)\n",
    "#     return math.sqrt(distance)\n",
    "# def Neighbor_points(train_d, test_d, k):\n",
    "#     distances = []\n",
    "#     length = len(test_d)-1\n",
    "#     for x in range(len(train_d)):\n",
    "#         dist = euclidDistance(test_d, train_d[x], length)\n",
    "#         distances.append((train_d[x], dist))\n",
    "#     distances.sort(key=lambda x: x[1])\n",
    "# #     print(distances)\n",
    "#     neighbors = []\n",
    "#     for x in range(k):\n",
    "#         neighbors.append(distances[x][0])\n",
    "# #         print(neighbors)\n",
    "#     return neighbors\n",
    "# def resultss(neighbors):\n",
    "#     predlabel = {}\n",
    "#     for x in range(len(neighbors)):\n",
    "#         res = neighbors[x][-1]\n",
    "#         if res not in predlabel:\n",
    "#             predlabel[res] = 1\n",
    "#         predlabel[res] += 1\n",
    "#     ans = sorted(predlabel.items(), reverse=True)\n",
    "#     return ans[0][0]\n",
    "# def accu_calc(test, predlabel):\n",
    "#     correct = 0\n",
    "#     for x in range(len(test)):\n",
    "#         if test[x][-1] == predlabel[x]:\n",
    "#             correct += 1\n",
    "#     return (correct/float(len(test))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test = train_test_split(df, test_size=0.2) \n",
    "# pre_values=[]\n",
    "# k = 5\n",
    "# train['Chance of Admit ']=np.where(train['Chance of Admit ']>=0.5,1,0)\n",
    "# test['Chance of Admit ']=np.where(test['Chance of Admit ']>=0.5,1,0)\n",
    "# test1=test\n",
    "# train1=train\n",
    "# test=test.values\n",
    "# train=train.values\n",
    "\n",
    "# for x in range(len(test)):\n",
    "#     neighbors = Neighbor_points(train, test[x], k)\n",
    "#     result = resultss(neighbors)\n",
    "#     pre_values.append(result)\n",
    "# accuracy = accu_calc(test, pre_values)\n",
    "# # print(pre_values)\n",
    "# print ('The Accuracy is: ', accuracy)\n",
    "# # test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
